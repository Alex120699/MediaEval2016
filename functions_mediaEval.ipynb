{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36cf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import sklearn\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import calinski_harabasz_score as qmetric\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import subprocess\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e959e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class handles_vars:\n",
    "    def __init__ (self):\n",
    "        self.Dir = str()\n",
    "        self.directorio = str()\n",
    "        self.algoritmo = int()\n",
    "        self.topic = int()\n",
    "        self.nametopic = str()\n",
    "        self.tipo_distancia = str()\n",
    "        self.clustering = str()\n",
    "        self.init_order = int()\n",
    "        self.Rlocation = str()\n",
    "        self.pca = int()\n",
    "        self.aleatorio = int()\n",
    "        self.maximoImagenVista = int()\n",
    "        self.owa = str()\n",
    "        self.weightsIt2 = list()\n",
    "        self.weigthsIt3 = list()\n",
    "        self.weightsCat2 = list()\n",
    "        self.weightsCat3 = list()\n",
    "        self.relevance0 = int()\n",
    "        self.sinqueries = int()\n",
    "        self.st = np.ndarray\n",
    "        self.variances_pca = np.ndarray\n",
    "        self.ajuste = str()\n",
    "        self.datosImagenes = np.ndarray\n",
    "        self.datos = np.ndarray\n",
    "        self.datosclusters = np.ndarray\n",
    "        self.topicneg = int()\n",
    "        self.datosclustervisual = np.ndarray\n",
    "        self.KmeansCentros = np.ndarray\n",
    "        self.KmeansDists = np.ndarray\n",
    "        self.KmeansSumas = np.ndarray\n",
    "        self.positivas = np.ndarray\n",
    "        self.queries = np.ndarray\n",
    "        self.imaRel = np.ndarray\n",
    "        self.imaRelHistorico = np.ndarray\n",
    "        self.imaProb = np.ndarray\n",
    "        self.imaProb1 = np.ndarray\n",
    "        self.imaProb2 = np.ndarray\n",
    "        self.imaProbHistoria = np.ndarray\n",
    "        self.datosyneg = np.ndarray\n",
    "        self.negativas = np.ndarray\n",
    "        self.datosyqueries = np.ndarray\n",
    "        self.datosorden = np.ndarray\n",
    "        self.datosyqueriesorden = np.ndarray\n",
    "        self.datosyqueriesynegativasorden = np.ndarray\n",
    "        self.Ranking = np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca14950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoCluster:\n",
    "    def __init__ (self):\n",
    "        self.id = int()\n",
    "        self.imagenes = np.ndarray\n",
    "        self.proba = np.ndarray\n",
    "        self.numimag = int()\n",
    "        self.probmax = float()\n",
    "        self.imagenmax = int()\n",
    "        self.idxquien = int()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36d478e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abrir_descriptores_mat(name_fmat):\n",
    "    descr_mat = scipy.io.loadmat(name_fmat)\n",
    "    #Convertimos el array n-dimensional en las diferentes listas\n",
    "    #Names\n",
    "    names = descr_mat[\"names\"]\n",
    "    #DatosImagenes\n",
    "    datosImagenes = descr_mat[\"datosImagenes\"]\n",
    "    #st\n",
    "    st = descr_mat[\"st\"]\n",
    "    #Variances PCA\n",
    "    variances_pca = descr_mat[\"variances_pca\"]\n",
    "    return names,datosImagenes,st,variances_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14acd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionoDescriptoresNeg(handles,maxnum,tipo):\n",
    "    # maxnum: número máximo de imágenes negativas a seleccionar\n",
    "    # tipo: algoritmo de selección de negativas\n",
    "    # 1: Selecciono las últimas ordenadas por su st\n",
    "    # 2: Selecciono del listado de imágenes pero de otro topic\n",
    "    # 3: Selecciono del listado de imágenes\n",
    "    if tipo == 1:\n",
    "        fil,col = handles.datos.shape\n",
    "        inici = fil - maxnum\n",
    "        descNR = handles.datos[inici:fil]\n",
    "        \n",
    "    elif tipo == 2:\n",
    "        if handles.topic<=70:\n",
    "            desp = 1\n",
    "            modulo = 70\n",
    "        else:\n",
    "            desp = 71\n",
    "            modulo = 65\n",
    "        numero = (handles.topic+1)%modulo + desp #De esta manera, obtengo siempre un topic diferente al nuestro del mismo set \n",
    "        handles.topicneg = numero\n",
    "        \n",
    "        #Cargamos el nuevo topic\n",
    "        name_fmat = os.path.join(handles.Dir,\"descriptores\",\"topic\")\n",
    "        name_fmat = name_fmat + str(handles.topicneg) + \".mat\"\n",
    "        names,datosImagenes,st,variances_pca = abrir_descriptores_mat(name_fmat)\n",
    "        \n",
    "        #ids_images = datosImagenes[:,0]\n",
    "        descNR = []\n",
    "        for i in range(maxnum):\n",
    "            descNR.append(datosImagenes[i,:])\n",
    "        \n",
    "        #Los tipos 3 y 4 se necesitan de un listado de imagenes\n",
    "        return handles,np.array(descNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de801616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_k_clusters(descr_image):\n",
    "    Nclusters_max = 15\n",
    "    Nrepetitions = 10\n",
    "\n",
    "    qualities = []\n",
    "    inertias = []\n",
    "    models = []\n",
    "    for k in range(1,Nclusters_max+1):\n",
    "        kmeans = KMeans(n_clusters=k,\n",
    "                        init='k-means++', n_init=Nrepetitions,\n",
    "                        max_iter=500, random_state=2)    \n",
    "        kmeans.fit(descr_image)\n",
    "        models.append(kmeans)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        if k >1:\n",
    "            qualities.append(qmetric(descr_image, kmeans.labels_))\n",
    "        else:\n",
    "            qualities.append(0)\n",
    "    \n",
    "    best = pd.Series(qualities).idxmax() # get index for the best model\n",
    "    kmeans = models[best]\n",
    "    n_clusters = kmeans.get_params()['n_clusters']\n",
    "    print(\"\\nEl numero optimo de clusters es de: \",n_clusters)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf6a6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerarClusteringVisual(handles,descr_imag,metodo,kclusters):\n",
    "    if metodo == \"kmeans18\":\n",
    "        dimension = 50\n",
    "        descr_redu = descr_imag\n",
    "        kmeans=KMeans(n_clusters=kclusters,random_state=0).fit(descr_redu)\n",
    "        #kmeans=KMeans(n_clusters=18,random_state=0).fit(handles.datos[:,2:])\n",
    "        \n",
    "        #Calculo la matriz que asigna a cada cluster las imagenes que contiene\n",
    "        clusterings = kmeans.labels_ \n",
    "        \n",
    "        #Calculo el centro de cada cluster para cada variable\n",
    "        centroids = kmeans.cluster_centers_ \n",
    "        \n",
    "        #Calculo la distancia de cada imagen al centro de cada cluster (euclidea)\n",
    "        dists = kmeans.transform(handles.datos[:,2:]) \n",
    "        \n",
    "        #Calculo la suma de las distancias de todos los puntos de un cluster a su centro para cada cluster\n",
    "        sumas=[]\n",
    "        for clus in np.unique(clusterings): #Del 0 al 17\n",
    "                images = np.argwhere(clusterings==clus) #Vector con las imagenes pertenecientes al cluster \"clus\"\n",
    "                sumas.append(dists[images,clus].sum()) #Sumamos las distancias de las imagenes pertenecientes al cluster clus hasta el centro de clus\n",
    "        sumas = np.array(sumas)\n",
    "        \n",
    "    elif metodo == \"kmeans_optimal\":\n",
    "        descr_redu = descr_imag\n",
    "        kmeans = optimal_k_clusters(descr_redu)\n",
    "        \n",
    "        #Calculo la matriz que asigna a cada cluster las imagenes que contiene\n",
    "        clusterings = kmeans.labels_ \n",
    "        \n",
    "        #Calculo el centro de cada cluster para cada variable\n",
    "        centroids = kmeans.cluster_centers_ \n",
    "        \n",
    "        #Calculo la distancia de cada imagen al centro de cada cluster (euclidea)\n",
    "        dists = kmeans.transform(handles.datos[:,2:]) \n",
    "        \n",
    "        #Calculo la suma de las distancias de todos los puntos de un cluster a su centro para cada cluster\n",
    "        sumas=[]\n",
    "        for clus in np.unique(clusterings): #Del 0 al 17\n",
    "                images = np.argwhere(clusterings==clus) #Vector con las imagenes pertenecientes al cluster \"clus\"\n",
    "                sumas.append(dists[images,clus].sum()) #Sumamos las distancias de las imagenes pertenecientes al cluster clus hasta el centro de clus\n",
    "        sumas = np.array(sumas)\n",
    "        \n",
    "    else:\n",
    "        print(\"Metodo no valido. Métodos disponibles: 'kmeans18','kmeans_optimal'\")\n",
    "    return clusterings,centroids,dists,sumas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "742691ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionImagenesPositivas(handles,tipoCluster,listado_neg):\n",
    "    # Esta función selecciona 5 imágenes positivas teniendo en cuenta su\n",
    "    # ranking textual st, i después teniendo en cuenta que no pertenecen al\n",
    "    # mismo cluster visual para tener imágenes relevantes pero que sean distintas\n",
    "    \n",
    "    #Numero de imagenes positivas que selecciono\n",
    "    num_positivas = 5\n",
    "    #tipoCluster\n",
    "    # 1: usamos cluster visual para seleccionar las imagenes positivas\n",
    "    # 2: usamos cluster textual para seleccionar las imagenes positivas\n",
    "    # 3: usamos cluster textual + visual para seleccionar las imagenes positivas\n",
    "    \n",
    "    if tipoCluster == 1:\n",
    "        #Tenemos que generar los clusters visuales\n",
    "        descr_image = handles.datos[:,2:] #Evitamos las dos primeras columnas que son name y name.jpg\n",
    "        \n",
    "        numclusters = 18\n",
    "        \n",
    "        handles.datosclustervisual,centroids,dists,sumas = GenerarClusteringVisual(handles,descr_image,handles.clustering,kclusters=numclusters)\n",
    "        identificadores = handles.datos[:,0]\n",
    "        #En este momento tenemos en datosclustervisual un vector de 300 filas donde a cada imagen le asignamos un cluster.\n",
    "        \n",
    "        #Ahora asociamos en una matriz de 300x2 el nombre de la imagen con su cluster\n",
    "        handles.datosclustervisual = np.c_[identificadores,handles.datosclustervisual]\n",
    "        handles.KmeansCentros = centroids\n",
    "        handles.KmeansDists = dists\n",
    "        handles.KmeansSumas = sumas\n",
    "        \n",
    "        imcluster = np.zeros(25) #Trabajamos con 25 clusters textuales, que luego mezclaremos con los 18 visuales\n",
    "        datoscluster = handles.datosclustervisual\n",
    "        \n",
    "    elif tipoCluster == 2:\n",
    "        datoscluster = handles.datosclusters\n",
    "        maximo = handles.datosclusters[:,1].max() #Selecciono el valor máximo que representa el número de clusters textuales\n",
    "        imcluster = np.zeros((1,maximo))\n",
    "    \n",
    "    elif tipoCluster == 3:\n",
    "        num_positivas = num_positivas*2\n",
    "        \n",
    "    #Si tenemos listado de imágenes negativas lo usamos para no seleccionar\n",
    "    # esa imagen como positiva (Existe= 1; No existe=0);\n",
    "    \n",
    "    if listado_neg == 0:\n",
    "        scoresTextual = handles.st[np.argsort(handles.st[:,1])]\n",
    "        ids = handles.datos[:,0]\n",
    "        \n",
    "        datosQueries = []\n",
    "        positivas = []\n",
    "        npositivas=0\n",
    "        i=0\n",
    "        \n",
    "        while (npositivas < num_positivas) and i+1 < scoresTextual.shape[0]:\n",
    "            im1 = int(scoresTextual[i,0]) #Cogemos la primera  (i-esima) imagen del ranking del scoreTextual\n",
    "            posi = np.argwhere(np.array(datoscluster)==im1)[0][0] #Calculamos su posicion en la matriz que la asocia a su cluster\n",
    "            idi = int(datoscluster[posi,0]) #Comprobamos que en esa posicion de la matriz tenemos a la imagen\n",
    "            cluster = int(datoscluster[posi,1]) #Extraemos el cluster al que pertenece\n",
    "            st = float(scoresTextual[i,2]) #Extraemos la probabilidad de la imagen del cluster en el ranking textual\n",
    "            pos = int(scoresTextual[i,1]) #Extraemos la posicion en el ranking de pertenecer al cluster\n",
    "            \n",
    "            if imcluster[cluster]==0:\n",
    "                c = 1\n",
    "                encontrado = 0\n",
    "                while (c==1 and (not encontrado)):\n",
    "                    total = np.argwhere(datoscluster[:,1]==cluster)\n",
    "                    \n",
    "                    if len(total) >=5:\n",
    "                        imcluster[cluster] = 1 \n",
    "                        positivas.append([idi, cluster, pos, st])\n",
    "                        #Busco los datos de la imagen Query en el listado de imágenes\n",
    "                        Impos = int(np.argwhere(ids==idi))\n",
    "                        datosQueries.append(handles.datos[Impos,:])\n",
    "                        npositivas+=1\n",
    "                        encontrado=1\n",
    "                    else:\n",
    "                        imcluster[cluster] = 1\n",
    "                    c+=1\n",
    "                    \n",
    "                if encontrado:\n",
    "                    imcluster[cluster]=1\n",
    "                i+=1\n",
    "            else:\n",
    "                i+=1\n",
    "    else:\n",
    "        print(\"No hay listado\")\n",
    "    handles.queries = np.array(datosQueries)\n",
    "    handles.positivas = np.array(positivas)\n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e35d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculoPesosModelo(variances,v_comp):\n",
    "    variances_norm = variances/variances.sum() #Suma 1\n",
    "    tam = len(v_comp)\n",
    "    pesos = np.zeros((tam,1))\n",
    "    inicio = 0\n",
    "    for i in range(tam):\n",
    "        fin = v_comp[i]+inicio\n",
    "        pesos[i] = variances_norm[inicio:fin].sum()\n",
    "        inicio = fin +1\n",
    "    \n",
    "    pesos = pesos/pesos.sum()\n",
    "    return pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68e0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AjusteMultiplesModelos(v_datos,lista_imag_rel,Rlocation,ajuste):\n",
    "    if ajuste==\"locfit\":\n",
    "        dimension = (lista_imag_rel==1).sum() #Numero de 1 en el vector\n",
    "        fil_datos,col_datos = v_datos.shape\n",
    "        inicio = 1\n",
    "        fin = dimension\n",
    "        vect_prob = []\n",
    "        v_componentesModelo = []\n",
    "\n",
    "        num = -1\n",
    "\n",
    "        while col_datos > inicio + fin:\n",
    "            DatosRegresion = np.hstack((v_datos[:,inicio-1:inicio+fin],lista_imag_rel))\n",
    "            #Guardamos los datos de regresion en un fichero\n",
    "            np.savetxt(\"fentrada.txt\",DatosRegresion)\n",
    "            #Ejecutamos el script de R que crea dos ficheros, relevancia.txt y componentes.txt\n",
    "            #relevancia.txt contiene una matriz con los datos de la regresion \n",
    "            #y con los -1 de las neutras convertidos en probabilidades de ser relevantes.\n",
    "            subprocess.call([Rlocation, '--vanilla', os.getcwd()+r\"/generoRelevancia.R\"]);\n",
    "\n",
    "            if 'relevancia.txt' in os.listdir():\n",
    "                proba_rel = np.array(pd.read_csv(os.getcwd()+r\"/relevancia.txt\",header=None))\n",
    "                n_comp = int(np.array(pd.read_csv(os.getcwd()+r\"/componentes.txt\",header=None)))\n",
    "\n",
    "                if len(proba_rel) == fil_datos:\n",
    "                    vect_prob.append(np.array(pd.read_csv(os.getcwd()+r\"/relevancia.txt\",header=None)))\n",
    "                    os.remove(\"relevancia.txt\")\n",
    "                    os.remove(\"componentes.txt\")\n",
    "                    v_componentesModelo.append(n_comp)\n",
    "            else:\n",
    "                cadena =f'No ha sido posible ajustar modelo multiple: {inicio}-{inicio+fin}'\n",
    "                print(cadena);\n",
    "                n_comp= fin\n",
    "\n",
    "            inicio = inicio + n_comp\n",
    "        \n",
    "        vect_prob = np.transpose(np.squeeze(np.array(vect_prob)))\n",
    "        v_componentesModelo = np.transpose(np.squeeze(np.array(v_componentesModelo)))\n",
    "        \n",
    "    elif ajuste==\"logistic\":\n",
    "        print(f\"v_datos: {v_datos.shape}\\n\\n\")\n",
    "        print(f\"lista_imag_rel: {lista_imag_rel.shape}\\n\\n\")\n",
    "        y_pos = lista_imag_rel[lista_imag_rel==1]\n",
    "        X_pos = v_datos[np.where(lista_imag_rel==1)[0]]\n",
    "        y_neg = lista_imag_rel[lista_imag_rel==0]\n",
    "        X_neg = v_datos[np.where(lista_imag_rel==0)[0]]\n",
    "        y_test = lista_imag_rel[lista_imag_rel==-1]\n",
    "        X_test = v_datos[np.where(lista_imag_rel==-1)[0]]\n",
    "        print(f\"X_pos: {X_pos.shape}\\n\")\n",
    "        print(f\"X_neg: {X_neg.shape}\\n\")\n",
    "        print(f\"y_pos: {y_pos.shape}\\n\")\n",
    "        print(f\"y_neg: {y_neg.shape}\\n\")\n",
    "        \n",
    "        X_train = np.vstack((X_pos,X_neg))\n",
    "        y_train = np.concatenate((y_pos,y_neg))\n",
    "        print(f\"X_train: {X_train.shape}\\n\")\n",
    "        print(f\"y_train: {y_train.shape}\\n\")\n",
    "        model = LogisticRegression(penalty=\"l2\")\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(X_test)[:,1]\n",
    "        vect_prob = model.predict_proba(X_test)\n",
    "        print(f\"Probabilidades test: {vect_prob.shape}\\n\")\n",
    "        print(vect_prob)\n",
    "        \n",
    "        \n",
    "    return vect_prob,v_componentesModelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9689c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClustersConImagenes(VectorClusters):\n",
    "    CantImagClust = [info.numimag for info in VectorClusters]\n",
    "    ClusConImg = np.array(CantImagClust) > 0\n",
    "    numclusters = ClusConImg.sum()\n",
    "    return numclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "824d5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ActualizarProbabilidadesClusters(VectorClusters):\n",
    "    numclusters = len(VectorClusters)\n",
    "    \n",
    "    for i in range(numclusters):\n",
    "        probmax = VectorClusters[i].proba.max()\n",
    "        idx = VectorClusters[i].proba.argmax()\n",
    "        VectorClusters[i].probmax = probmax\n",
    "        imagenmax = VectorClusters[i].imagenes[idx]\n",
    "        VectorClusters[i].imagenmax = imagenmax\n",
    "        VectorClusters[i].idxquien = idx\n",
    "    return VectorClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d9dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodoOrdenarPorClusters(imag_prob,losclusters, umbral):\n",
    "    VectorClusters = []\n",
    "    valoresclusters = np.unique(losclusters[:,1])\n",
    "\n",
    "    for cluster in valoresclusters:\n",
    "        info_clus = InfoCluster()\n",
    "        info_clus.id = cluster #Empiezo por el cluster 1\n",
    "        indices = np.argwhere(losclusters[:,1]==cluster) #Busco los indices que pertecen al cluster\n",
    "        info_clus.imagenes = losclusters[indices,0] #Selecciono las imagenes que pertenecen al cluster mediante su indice\n",
    "        \n",
    "        #Para cada imagen del cluster, busco la probabilidad en el otro vector\n",
    "        info_clus.proba = np.zeros((len(info_clus.imagenes),1))\n",
    "        info_clus.numimag = len(info_clus.imagenes)\n",
    "        \n",
    "        for j,imagen in enumerate(info_clus.imagenes):\n",
    "            ids = imagen\n",
    "            inde_img = np.argwhere(imag_prob[:,0]==ids)\n",
    "            info_clus.proba[j] = imag_prob[inde_img,1]\n",
    "        \n",
    "        probmax = info_clus.proba.max()\n",
    "        idx = info_clus.proba.argmax()\n",
    "        info_clus.probmax = probmax\n",
    "        imagenmax = info_clus.imagenes[idx]\n",
    "        info_clus.imagenmax = imagenmax\n",
    "        info_clus.idxquien = idx\n",
    "        VectorClusters.append(info_clus)\n",
    "    \n",
    "    \n",
    "    #VectorClusters es una lista que contiene objetos de la clase \"info_clus\", que contienen información acerca de un cluster\n",
    "    #como las imágenes que pertenecen a ese cluster y sus probabilidades (con eso se puede sacar el maximo y demás cosas)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Listaordenada = np.array(VectorClusters)\n",
    "    #print(\"Tenemos en una lista la información relativa a las imágenes respecto cada cluster\")\n",
    "    #print(\"POR EJEMPLO:\")\n",
    "    #print(f\"Cluster {VectorClusters[0].id}\\nTiene {VectorClusters[0].numimag} imágenes que son: {VectorClusters[0].imagenes}\")\n",
    "    #print(f\"Las probabilidades de cada imagen de ser relevantes en la búsqueda del Albuquerque Globos son: {VectorClusters[0].proba} \")\n",
    "    #print(f\"Nos guardamos entonces la más probable:\\n\")\n",
    "    #print(f\"La imagen numero {VectorClusters[0].idxquien} llamada {VectorClusters[0].imagenmax} con una probabilidad de {VectorClusters[0].probmax}\")\n",
    "    \n",
    "    #Recorro una vez las clusters y asigno una primera imagen de cada cluster\n",
    "    numclusters = len(Listaordenada)  \n",
    "    Ranking = []\n",
    "    continuar = True\n",
    "    vueltas = 1\n",
    "    while continuar:\n",
    "        #Asigno clusters\n",
    "        #Miro cuantos clusters hay actualmente con imagenes\n",
    "        numclusters = ClustersConImagenes(Listaordenada)\n",
    "        i = 1\n",
    "        seguir = 1\n",
    "        while seguir:\n",
    "            #Tomo 1 por cluster\n",
    "            #Me quedo con un vector con las probabilidades maximas de cada cluster de ser relevantes a la busqueda\n",
    "            proba_max_clus = np.array([lista.probmax for lista in Listaordenada])\n",
    "            \n",
    "            #Me guardo el valor de la probabilidad máxima de entre todos los clusters, su posicion (cluster) y el nombre de la imagen\n",
    "            maximo = proba_max_clus.max()\n",
    "            idx = proba_max_clus.argmax()\n",
    "            idimagen = int(Listaordenada[idx].imagenmax)\n",
    "            \n",
    "            #guardo identificador de imagen, probabilidad y cluster\n",
    "            #puedo poner un filtro de probabilidad\n",
    "            \n",
    "            if maximo > umbral:\n",
    "                if len(Ranking)==0:\n",
    "                    Ranking.append([int(idimagen),maximo*10000,Listaordenada[idx].id])\n",
    "                else:\n",
    "                    if len(np.argwhere(np.array(Ranking,dtype=\"object\")[:,0]==idimagen))==0:\n",
    "                        Ranking.append([int(idimagen),maximo*10000,Listaordenada[idx].id])\n",
    "                        \n",
    "            ind_clust = np.argwhere(losclusters[:,0]==idimagen)\n",
    "            id_clusters = losclusters[ind_clust,1]\n",
    "            lista_id = np.array([lista.id for lista in Listaordenada])\n",
    "            #Elimino el cluster de la lista y su probmax\n",
    "            Listaordenada[idx].probmax = -1\n",
    "            #Tambien marco la imagen y su probabilidad como ya utilizada\n",
    "            indpos = np.argwhere(Listaordenada[idx].imagenes == idimagen)[0][0]\n",
    "            #En todas las imagenes de ese cluster que sean igual a la idimagen\n",
    "            Listaordenada[idx].proba[indpos] = -1\n",
    "            \n",
    "            #quito la imagen de otros posibles clusterings, \n",
    "            #quito la probabilidad maxima\n",
    "            \n",
    "            for j in range(len(id_clusters)):\n",
    "                #encuentro la posicion de los otros cluster donde esta la imagen\n",
    "                #busco cada cluster j \n",
    "                posicion = int(np.argwhere(lista_id == id_clusters[j]))\n",
    "                #REVISAR ESTE CODIGO\n",
    "                \n",
    "                if posicion != idx:\n",
    "                    #Encuentro las imagenes que son iguales en los otros clusters, pero el cluster no lo marco como\n",
    "                    indpos = np.argwhere(Listaordenada[posicion].imagenes == idimagen)\n",
    "                    #elimino de todos los otros clusters esa imagen poniendo la prob a -1\n",
    "                    Listaordenada[posicion].proba[indpos] = -1\n",
    "                    #Contamos cuantas imagenes elimino\n",
    "                    cantidad = len(indpos)\n",
    "                    Listaordenada[posicion].numimag = Listaordenada[posicion].numimag - cantidad\n",
    "                    #Actualizo la probabilidad del cluster\n",
    "                    probmax = Listaordenada[posicion].proba.max()\n",
    "                    idx2 = Listaordenada[posicion].proba.argmax()\n",
    "                    \n",
    "                    if Listaordenada[posicion].probmax != -1: #solo actualizo si el cluster no esta eliminado\n",
    "                        Listaordenada[posicion].probmax = probmax\n",
    "                    #Actualizo que imagen es la que da esa probabilidad\n",
    "                    Listaordenada[posicion].imagenmax = Listaordenada[posicion].imagenes[idx2]\n",
    "                    \n",
    "            indclus = np.argwhere(np.array([lista.probmax for lista in Listaordenada])>umbral)\n",
    "            \n",
    "            if len(indclus)==0:\n",
    "                seguir = False\n",
    "        Listaordenada = ActualizarProbabilidadesClusters(Listaordenada)\n",
    "        numclusters = ClustersConImagenes(Listaordenada)\n",
    "        \n",
    "        if numclusters==0:\n",
    "            continuar = False\n",
    "        if (vueltas>=12) or (len(Ranking)>50):\n",
    "            continuar = False\n",
    "        vueltas += 1\n",
    "        \n",
    "    Listaordenada = VectorClusters\n",
    "    \n",
    "    return Listaordenada,Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e91e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodoMediaEval(handles,runvisual):\n",
    "    #Juntamos todos los datos\n",
    "    handles.datosyqueriesynegativasorden = np.vstack((handles.negativas,handles.datosyqueriesorden))\n",
    "    \n",
    "    cantidad,tam = handles.datosyqueriesynegativasorden.shape\n",
    "    cantidadpos,tam2 = handles.queries.shape\n",
    "    cantidadneg,tam3 = handles.negativas.shape\n",
    "    \n",
    "    #Asigno con -1 a las neutras, con 0 a las negativas y con 1 a las positivas\n",
    "    relevanciaOrdenInicial = np.ones((cantidad,1))*-1\n",
    "    relevanciaOrdenInicial[:cantidadneg] = 0\n",
    "    relevanciaOrdenInicial[cantidad-cantidadpos:] = 1\n",
    "    \n",
    "    lista_imag_rel = relevanciaOrdenInicial\n",
    "    Rlocation = handles.Rlocation\n",
    "    v_datos = handles.datosyqueriesynegativasorden[:,2:]\n",
    "    \n",
    "    if handles.ajuste==\"logistic\"\n",
    "        #Ajustamos un modelo en R con los v_datos como matriz X de entrenamiento y lista_imag_rel como Y a predecir\n",
    "        vect_prob,v_componentesModelo = AjusteMultiplesModelos(v_datos,lista_imag_rel,Rlocation,handles.ajuste)\n",
    "        pesos = CalculoPesosModelo(handles.variances_pca,v_componentesModelo)\n",
    "        proba_rel = np.matmul(vect_prob,pesos)\n",
    "        proba_rel = proba_rel[cantidadneg:]\n",
    "        identificadores = handles.datosyqueriesorden[:,0]\n",
    "        prob_result = np.c_[identificadores,proba_rel]\n",
    "        imag_prob = prob_result[:-cantidadpos]\n",
    "        \n",
    "    umbralprob = 0.2\n",
    "    \n",
    "    if runvisual==1:\n",
    "        clusters = handles.datosclustervisual\n",
    "    else:\n",
    "        clusters = handles.datosclusters\n",
    "    \n",
    "    VectorClusters,Ranking = metodoOrdenarPorClusters(imag_prob,clusters,umbralprob)\n",
    "    \n",
    "    #Convierto Ranking en un array por comodidad\n",
    "    Ranking = np.array(Ranking,dtype=\"object\")\n",
    "    \n",
    "    res_tmp = handles.st\n",
    "    img_text = np.c_[handles.st[:,0],handles.st[:,2]]\n",
    "    \n",
    "    handles.Ranking = Ranking\n",
    "    \n",
    "    #Guardamos Ranking en un fichero\n",
    "    with open(\"Ranking.txt\", \"w\",newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(Ranking)\n",
    "    \n",
    "    filpr, colpr = prob_result.shape\n",
    "    score = []\n",
    "    n_clus = []\n",
    "    for i in range(filpr - cantidadpos):\n",
    "        idimag = imag_prob[i,0]\n",
    "        indice = np.argwhere(Ranking[:,0]==idimag)\n",
    "        if not indice.size==0:\n",
    "            score.append(indice[0][1])\n",
    "            n_clus.append(Ranking[indice[0][1],2])\n",
    "        else:\n",
    "            score.append(1000)\n",
    "            n_clus.append(-1) #No viene de ningun cluster\n",
    "            \n",
    "    score = np.array(score,dtype=\"object\")\n",
    "    n_clus = np.array(n_clus,dtype=\"object\")\n",
    "    \n",
    "    #Creamos una matriz con las el nombre de las imagenes, su posicion en el ranking (1000) en caso de no aparecer y el cluster \n",
    "    #al que pertenecen (-1 si no estan en el ranking)\n",
    "    prob_result = np.c_[(imag_prob[:,0],score,n_clus)]\n",
    "    \n",
    "    #Ordenamos esta matriz en base a la posicion del ranking y nos guardamos las posiciones que tenian\n",
    "    \n",
    "    ResultadoOrdenado = np.sort(score)\n",
    "    aux = np.argsort(score)\n",
    "    \n",
    "    handles.datos = handles.datosorden[aux,:]\n",
    "    \n",
    "    #Añadimos las queries al final con sus scores\n",
    "    filas_queries,col_queries = handles.queries.shape\n",
    "    \n",
    "    handles.datosyqueries = np.vstack((handles.datos,handles.queries))\n",
    "    \n",
    "    scoreQueries = np.ones(filas_queries)*1000\n",
    "    \n",
    "    #handles.imaProb = np.vstack((Ranking[:,1],scoreQueries))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return handles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06566ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMediaEvalResults(handles,fp):\n",
    "\n",
    "    iteracion = 0\n",
    "\n",
    "    if handles.algoritmo == 1:\n",
    "        run_id = 'run1_visual'\n",
    "    elif handles.algoritmo == 3:\n",
    "        run_id = 'run3_multimedia'\n",
    "    elif handles.algoritmo == 5:\n",
    "        run_id = 'run5_relfeedback'\n",
    "\n",
    "    sim = 1.0\n",
    "    tam = len(handles.Ranking)\n",
    "    minimo = min(50,tam)\n",
    "\n",
    "    for i in range(minimo):\n",
    "        rank = i\n",
    "        fp.write(f\"{handles.topic} {iteracion} {handles.Ranking[i,0]} {rank} {sim} {run_id}\\n\")\n",
    "        sim = round(sim-0.01,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
